{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m image \u001b[38;5;241m=\u001b[39m load_image(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal-996.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Explain the prediction for the example image\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m explanation_image \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Display the original and explained images\u001b[39;00m\n\u001b[0;32m     67\u001b[0m explainer\u001b[38;5;241m.\u001b[39mdisplay_explanation(image, explanation_image)\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36mLimeExplainer.explain\u001b[1;34m(self, image, top_labels, num_samples, num_features, segmentation_fn)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, segmentation_fn\u001b[38;5;241m=\u001b[39mslic):\n\u001b[1;32m---> 33\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhide_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43msegmentation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegmentation_fn\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     temp, mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(\n\u001b[0;32m     43\u001b[0m         explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     44\u001b[0m         positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     45\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[0;32m     46\u001b[0m         hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     )\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mark_boundaries(temp \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m, mask)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\lime\\lime_image.py:172\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, classifier_fn, labels\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,),\n\u001b[0;32m    130\u001b[0m                      hide_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m                      top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m                      model_regressor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    136\u001b[0m                      random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates explanations for a prediction.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    First, we generate neighborhood data by randomly perturbing features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m        explanations.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    173\u001b[0m         image \u001b[38;5;241m=\u001b[39m gray2rgb(image)\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random_seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\PIL\\Image.py:528\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    526\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "import lime\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The loaded image.\n",
    "    \"\"\"\n",
    "    return Image.open(image_path)\n",
    "\n",
    "class LimeExplainer:\n",
    "    def __init__(self, model, input_shape):\n",
    "        self.model = model\n",
    "        self.input_shape = input_shape\n",
    "        self.explainer = lime_image.LimeImageExplainer()\n",
    "    \n",
    "    def predict_fn(self, images):\n",
    "        images = np.stack([resize(image, self.input_shape) for image in images])\n",
    "        return self.model.predict(images)\n",
    "    \n",
    "    def explain(self, image, top_labels=1, num_samples=100, num_features=5, segmentation_fn=slic):\n",
    "        explanation = self.explainer.explain_instance(\n",
    "            image,\n",
    "            self.predict_fn,\n",
    "            top_labels=top_labels,\n",
    "            hide_color=0,\n",
    "            num_samples=num_samples,\n",
    "            segmentation_fn=segmentation_fn\n",
    "        )\n",
    "        \n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0],\n",
    "            positive_only=False,\n",
    "            num_features=num_features,\n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        return mark_boundaries(temp / 2 + 0.5, mask)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Load your model and define input_shape\n",
    "    model = load_model('trainedmodel.h5')\n",
    "    input_shape = (128, 128, 3)  # Adjust according to your model input shape\n",
    "    \n",
    "    # Create LimeExplainer object\n",
    "    explainer = LimeExplainer(model, input_shape)\n",
    "    \n",
    "    # Load your image\n",
    "    image = load_image('Normal-996.png')  # Replace with your image path\n",
    "    \n",
    "    # Explain the prediction for the example image\n",
    "    explanation_image = explainer.explain(image)\n",
    "    \n",
    "    # Display the original and explained images\n",
    "    explainer.display_explanation(image, explanation_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.PngImagePlugin.PngImageFile'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m image \u001b[38;5;241m=\u001b[39m load_image(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal-996.png\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(image))\n\u001b[1;32m---> 62\u001b[0m explanation_image \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Explain the prediction for the example image\u001b[39;00m\n\u001b[0;32m     65\u001b[0m explanation_image \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain(image)\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mLimeExplainer.explain\u001b[1;34m(self, image, top_labels, num_samples, num_features, segmentation_fn)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, segmentation_fn\u001b[38;5;241m=\u001b[39mslic):\n\u001b[1;32m---> 32\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhide_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43msegmentation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegmentation_fn\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     temp, mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(\n\u001b[0;32m     42\u001b[0m         explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     43\u001b[0m         positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[0;32m     45\u001b[0m         hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mark_boundaries(temp \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m, mask)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\lime\\lime_image.py:172\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain_instance\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, classifier_fn, labels\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,),\n\u001b[0;32m    130\u001b[0m                      hide_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m                      top_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m                      model_regressor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    136\u001b[0m                      random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates explanations for a prediction.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m    First, we generate neighborhood data by randomly perturbing features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m        explanations.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    173\u001b[0m         image \u001b[38;5;241m=\u001b[39m gray2rgb(image)\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random_seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\PIL\\Image.py:528\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    526\u001b[0m     deprecate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage categories\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_animated\u001b[39m\u001b[38;5;124m\"\u001b[39m, plural\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_category\n\u001b[1;32m--> 528\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: shape"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.transform import resize\n",
    "import lime\n",
    "from lime.lime_image import LimeImageExplainer\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The loaded image.\n",
    "    \"\"\"\n",
    "    return Image.open(image_path)\n",
    "\n",
    "class LimeExplainer:\n",
    "    def __init__(self, model, input_shape):\n",
    "        self.model = model\n",
    "        self.input_shape = input_shape\n",
    "        self.explainer = LimeImageExplainer()\n",
    "    \n",
    "    def predict_fn(self, images):\n",
    "        images = np.stack([resize(image, self.input_shape) for image in images])\n",
    "        return self.model.predict(images)\n",
    "    \n",
    "    def explain(self, image, top_labels=1, num_samples=100, num_features=5, segmentation_fn=slic):\n",
    "        explanation = self.explainer.explain_instance(\n",
    "            image,\n",
    "            self.predict_fn,\n",
    "            top_labels=top_labels,\n",
    "            hide_color=0,\n",
    "            num_samples=num_samples,\n",
    "            segmentation_fn=segmentation_fn\n",
    "        )\n",
    "        \n",
    "        temp, mask = explanation.get_image_and_mask(\n",
    "            explanation.top_labels[0],\n",
    "            positive_only=False,\n",
    "            num_features=num_features,\n",
    "            hide_rest=False\n",
    "        )\n",
    "        \n",
    "        return mark_boundaries(temp / 2 + 0.5, mask)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # Load your model and define input_shape\n",
    "    model = load_model('trainedmodel.h5')\n",
    "    input_shape = (128, 128, 3)  # Adjust according to your model input shape\n",
    "    \n",
    "    # Create LimeExplainer object\n",
    "    explainer = LimeExplainer(model, input_shape)\n",
    "    \n",
    "    # Load your image\n",
    "    image = load_image('Normal-996.png')  # Replace with your image path\n",
    "    print(type(image))\n",
    "    explanation_image = explainer.explain(image)\n",
    "\n",
    "    # Explain the prediction for the example image\n",
    "    explanation_image = explainer.explain(image)\n",
    "    \n",
    "    # Display the original and explained images\n",
    "    explainer.display_explanation(image, explanation_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
